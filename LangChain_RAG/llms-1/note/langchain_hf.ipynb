{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Huggingface \n\n`Huggingface`提供了两种方式调用LLM\n1. 通过Api token 的方式\n2. 本地加载\n","metadata":{}},{"cell_type":"markdown","source":"## 安装环境","metadata":{}},{"cell_type":"code","source":"! pip install langchain huggingface_hub transformers sentence_transformers accelerate bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:50:24.280613Z","iopub.execute_input":"2024-05-08T22:50:24.281548Z","iopub.status.idle":"2024-05-08T22:50:51.323227Z","shell.execute_reply.started":"2024-05-08T22:50:24.281508Z","shell.execute_reply":"2024-05-08T22:50:51.321936Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nCollecting sentence_transformers\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nCollecting langchain-community<0.1,>=0.0.36 (from langchain)\n  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\nCollecting langchain-core<0.2.0,>=0.1.48 (from langchain)\n  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.56-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nCollecting packaging>=20.9 (from huggingface_hub)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m774.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading langchain-0.1.17-py3-none-any.whl (867 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.56-py3-none-any.whl (120 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, bitsandbytes, langchain-core, sentence_transformers, langchain-text-splitters, langchain-community, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.43.1 langchain-0.1.17 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langsmith-0.1.56 orjson-3.10.3 packaging-23.2 sentence_transformers-2.7.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 使用API  token 调用LLM","metadata":{}},{"cell_type":"code","source":"from getpass import getpass\n\nHUGGINGFACEHUB_API_TOKEN = getpass()","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:57:29.227965Z","iopub.execute_input":"2024-05-08T22:57:29.228623Z","iopub.status.idle":"2024-05-08T22:57:34.921734Z","shell.execute_reply.started":"2024-05-08T22:57:29.228589Z","shell.execute_reply":"2024-05-08T22:57:34.920698Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdin","text":" ·····································\n"}]},{"cell_type":"code","source":"import os\n\nos.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:57:38.064912Z","iopub.execute_input":"2024-05-08T22:57:38.065339Z","iopub.status.idle":"2024-05-08T22:57:38.070427Z","shell.execute_reply.started":"2024-05-08T22:57:38.065311Z","shell.execute_reply":"2024-05-08T22:57:38.069252Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from langchain_community.llms import HuggingFaceHub\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:57:38.672299Z","iopub.execute_input":"2024-05-08T22:57:38.672709Z","iopub.status.idle":"2024-05-08T22:57:38.678286Z","shell.execute_reply.started":"2024-05-08T22:57:38.672667Z","shell.execute_reply":"2024-05-08T22:57:38.677158Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"### 创建prompt 模板\nquestion = \"Where is the capital of China? \"\n\ntemplate = \"\"\"Question: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\" ])","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:57:39.963940Z","iopub.execute_input":"2024-05-08T22:57:39.964334Z","iopub.status.idle":"2024-05-08T22:57:39.969719Z","shell.execute_reply.started":"2024-05-08T22:57:39.964306Z","shell.execute_reply":"2024-05-08T22:57:39.968740Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"repo_id = \"google/flan-t5-base\"  # 具体可以参考 https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads ","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:57:41.632481Z","iopub.execute_input":"2024-05-08T22:57:41.632896Z","iopub.status.idle":"2024-05-08T22:57:41.637979Z","shell.execute_reply.started":"2024-05-08T22:57:41.632863Z","shell.execute_reply":"2024-05-08T22:57:41.636856Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"llm = HuggingFaceHub(\n    repo_id=repo_id, \n)\nllm_chain = LLMChain(prompt=prompt, llm=llm  , llm_kwargs = {\"temperature\":0, \"max_length\":512})\n\nprint(llm_chain.run(question))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:57:43.111129Z","iopub.execute_input":"2024-05-08T22:57:43.111933Z","iopub.status.idle":"2024-05-08T22:57:43.241551Z","shell.execute_reply.started":"2024-05-08T22:57:43.111892Z","shell.execute_reply":"2024-05-08T22:57:43.240409Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"China is located in the north of the world. The capital of China is Beijing. The answer: Beijing.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 构建RAG检索","metadata":{}},{"cell_type":"code","source":"! pip install pypdf  faiss-cpu","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:52:15.563323Z","iopub.execute_input":"2024-05-08T22:52:15.563616Z","iopub.status.idle":"2024-05-08T22:52:31.008324Z","shell.execute_reply.started":"2024-05-08T22:52:15.563591Z","shell.execute_reply":"2024-05-08T22:52:31.007136Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (4.2.0)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nRequirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.10/site-packages (from pypdf) (4.9.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\nDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.document_loaders import PyPDFLoader\n\n###加载文件\nloader = PyPDFLoader(\"https://arxiv.org/pdf/2309.10305.pdf\")\npages = loader.load()\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n###文本切分\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size = 300,chunk_overlap = 50,)\n\ndocs = text_splitter.split_documents(pages[:4])","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:52:31.010158Z","iopub.execute_input":"2024-05-08T22:52:31.010515Z","iopub.status.idle":"2024-05-08T22:52:33.174692Z","shell.execute_reply.started":"2024-05-08T22:52:31.010481Z","shell.execute_reply":"2024-05-08T22:52:33.173608Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\nfrom langchain_community.vectorstores import FAISS\n\n\nembeddings = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ndb = FAISS.from_documents(docs, embeddings)\n\nquery = \"How large is the baichuan2 vocabulary size?\"\nresult_simi = db.similarity_search(query , k = 3)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:52:33.178137Z","iopub.execute_input":"2024-05-08T22:52:33.178426Z","iopub.status.idle":"2024-05-08T22:52:33.768962Z","shell.execute_reply.started":"2024-05-08T22:52:33.178401Z","shell.execute_reply":"2024-05-08T22:52:33.768035Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"source_knowledge = \"\\n\".join([x.page_content for x in result_simi])","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:52:33.770280Z","iopub.execute_input":"2024-05-08T22:52:33.770597Z","iopub.status.idle":"2024-05-08T22:52:33.775870Z","shell.execute_reply.started":"2024-05-08T22:52:33.770570Z","shell.execute_reply":"2024-05-08T22:52:33.774657Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"augmented_prompt = \"\"\"Using the contexts below, answer the query.\n\ncontexts:\n{source_knowledge}\n\nquery: {query}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:52:33.777158Z","iopub.execute_input":"2024-05-08T22:52:33.777510Z","iopub.status.idle":"2024-05-08T22:52:33.789505Z","shell.execute_reply.started":"2024-05-08T22:52:33.777476Z","shell.execute_reply":"2024-05-08T22:52:33.788704Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"prompt = PromptTemplate(template=augmented_prompt, input_variables=[\"source_knowledge\" ,\"query\"])\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llm  , llm_kwargs = {\"temperature\":0, \"max_length\":1024})\n\nprint(llm_chain.run( {\"source_knowledge\":source_knowledge ,\"query\" : query }))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:52:33.790688Z","iopub.execute_input":"2024-05-08T22:52:33.790952Z","iopub.status.idle":"2024-05-08T22:52:33.839454Z","shell.execute_reply.started":"2024-05-08T22:52:33.790929Z","shell.execute_reply":"2024-05-08T22:52:33.838568Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"125,696\n","output_type":"stream"}]},{"cell_type":"code","source":"augmented_prompt_2 = f\"\"\"Using the contexts below, answer the query.\n\ncontexts:\n{source_knowledge}\n\nquery: {query}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:52:33.840323Z","iopub.execute_input":"2024-05-08T22:52:33.840618Z","iopub.status.idle":"2024-05-08T22:52:33.844858Z","shell.execute_reply.started":"2024-05-08T22:52:33.840598Z","shell.execute_reply":"2024-05-08T22:52:33.843821Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(augmented_prompt_2)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:52:33.846155Z","iopub.execute_input":"2024-05-08T22:52:33.846489Z","iopub.status.idle":"2024-05-08T22:52:33.854762Z","shell.execute_reply.started":"2024-05-08T22:52:33.846459Z","shell.execute_reply":"2024-05-08T22:52:33.853822Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Using the contexts below, answer the query.\n\ncontexts:\nhave taken both these aspects into account. We\nhave expanded the vocabulary size from 64,000\nin Baichuan 1 to 125,696, aiming to strike a\nbalance between computational efficiency and\nmodel performance.\nTokenizer V ocab Size Compression Rate ↓\nLLaMA 2 32,000 1.037\nBloom 250,680 0.501\nimprove after training on more than 2.6 trillion\ntokens. By sharing these intermediary results,\nwe hope to provide the community with greater\ninsight into the training dynamics of Baichuan 2.\nUnderstanding these dynamics is key to unraveling\nthe inner working mechanism of large language\nBaichuan 2: Open Large-scale Language Models\nAiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan\nDian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai\nGuosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji\n\nquery: How large is the baichuan2 vocabulary size?\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 本地加载LLM\n\n- baichuan model 为例","metadata":{}},{"cell_type":"code","source":"! pip install modelscope\n#  safetensors xformers\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:52:33.855963Z","iopub.execute_input":"2024-05-08T22:52:33.856293Z","iopub.status.idle":"2024-05-08T22:53:01.493516Z","shell.execute_reply.started":"2024-05-08T22:52:33.856269Z","shell.execute_reply":"2024-05-08T22:53:01.492372Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Collecting modelscope\n  Downloading modelscope-1.14.0-py3-none-any.whl.metadata (33 kB)\nCollecting addict (from modelscope)\n  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from modelscope) (23.2.0)\nRequirement already satisfied: datasets<2.19.0,>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.18.0)\nCollecting einops (from modelscope)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (3.13.1)\nRequirement already satisfied: gast>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.5.4)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.22.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.26.4)\nCollecting oss2 (from modelscope)\n  Downloading oss2-2.18.5.tar.gz (283 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.4/283.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.1.4)\nRequirement already satisfied: Pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (9.5.0)\nRequirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (15.0.2)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.9.0.post0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from modelscope) (6.0.1)\nRequirement already satisfied: requests>=2.25 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.31.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.11.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from modelscope) (69.0.3)\nRequirement already satisfied: simplejson>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (3.19.2)\nRequirement already satisfied: sortedcontainers>=1.5.9 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.4.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (4.66.1)\nRequirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.26.18)\nRequirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.40.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets<2.19.0,>=2.16.0->modelscope) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (3.9.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (23.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->modelscope) (4.9.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.1->modelscope) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (2024.2.2)\nRequirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope) (1.7)\nRequirement already satisfied: pycryptodome>=3.4.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope) (3.20.0)\nCollecting aliyun-python-sdk-kms>=2.4.1 (from oss2->modelscope)\n  Downloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting aliyun-python-sdk-core>=2.13.12 (from oss2->modelscope)\n  Downloading aliyun-python-sdk-core-2.15.1.tar.gz (443 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope) (2023.4)\nRequirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->modelscope) (6.11.0)\nRequirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->modelscope) (4.2.0)\nRequirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->modelscope) (2.0.1)\nCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope)\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (41.0.7)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (4.0.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->modelscope) (3.17.0)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (2.21)\nDownloading modelscope-1.14.0-py3-none-any.whl (5.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nBuilding wheels for collected packages: oss2, aliyun-python-sdk-core\n  Building wheel for oss2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for oss2: filename=oss2-2.18.5-py3-none-any.whl size=118146 sha256=f7f09e2c6de222c9a8e5dd333bfe328fc320ce44d5e9f1c1a533520ac9cbc14b\n  Stored in directory: /root/.cache/pip/wheels/c5/ec/94/a908b823ad209d91fb3cb809c0553032e496dd3d36218e4596\n  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.1-py3-none-any.whl size=535325 sha256=5896a7cfe3c84fa6e049c2989cac67e65040bcf012c67706dd4c12f97a363a9e\n  Stored in directory: /root/.cache/pip/wheels/69/4b/8e/0a28e00f4cf43b273c18cce083804738d41013e017da922ce4\nSuccessfully built oss2 aliyun-python-sdk-core\nInstalling collected packages: addict, jmespath, einops, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, modelscope\n  Attempting uninstall: jmespath\n    Found existing installation: jmespath 1.0.1\n    Uninstalling jmespath-1.0.1:\n      Successfully uninstalled jmespath-1.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nboto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.34.69 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed addict-2.4.0 aliyun-python-sdk-core-2.15.1 aliyun-python-sdk-kms-2.16.3 einops-0.8.0 jmespath-0.10.0 modelscope-1.14.0 oss2-2.18.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers.generation.utils import GenerationConfig","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:53:01.495212Z","iopub.execute_input":"2024-05-08T22:53:01.495597Z","iopub.status.idle":"2024-05-08T22:53:09.120921Z","shell.execute_reply.started":"2024-05-08T22:53:01.495560Z","shell.execute_reply":"2024-05-08T22:53:09.120028Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom modelscope import snapshot_download, Model\nmodel_dir = snapshot_download(\"baichuan-inc/Baichuan2-7B-Chat\", revision='master')\nmodel = Model.from_pretrained(model_dir, device_map=\"auto\", trust_remote_code=True, torch_dtype=torch.float16)\nmessages = []\nmessages.append({\"role\": \"user\", \"content\": \"讲解一下“温故而知新”\"})\nresponse = model(messages)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:53:09.122138Z","iopub.execute_input":"2024-05-08T22:53:09.122608Z","iopub.status.idle":"2024-05-08T22:57:06.228086Z","shell.execute_reply.started":"2024-05-08T22:53:09.122575Z","shell.execute_reply":"2024-05-08T22:57:06.226745Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2024-05-08 22:53:09,573 - modelscope - INFO - PyTorch version 2.1.2 Found.\n2024-05-08 22:53:09,577 - modelscope - INFO - TensorFlow version 2.15.0 Found.\n2024-05-08 22:53:09,578 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n2024-05-08 22:53:09,579 - modelscope - INFO - No valid ast index found from /root/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n2024-05-08 22:53:09,664 - modelscope - INFO - Loading done! Current index file version is 1.14.0, with md5 2b7176df9ec6b1a9ffe207a78dcc5d2e and a total number of 976 components indexed\n2024-05-08 22:53:10,979 - modelscope - WARNING - Using the master branch is fragile, please use it with caution!\n2024-05-08 22:53:10,980 - modelscope - INFO - Use user-specified model revision: master\nDownloading: 100%|██████████| 252k/252k [00:00<00:00, 1.25MB/s]\nDownloading: 100%|██████████| 198k/198k [00:00<00:00, 1.22MB/s]\nDownloading: 100%|██████████| 758/758 [00:00<00:00, 3.14MB/s]\nDownloading: 100%|██████████| 215/215 [00:00<00:00, 881kB/s]\nDownloading: 100%|██████████| 2.39k/2.39k [00:00<00:00, 8.81MB/s]\nDownloading: 100%|██████████| 285/285 [00:00<00:00, 412kB/s]\nDownloading: 100%|██████████| 2.90k/2.90k [00:00<00:00, 13.4MB/s]\nDownloading: 100%|██████████| 32.5k/32.5k [00:00<00:00, 822kB/s]\nDownloading: 100%|██████████| 3.28k/3.28k [00:00<00:00, 15.3MB/s]\nDownloading: 100%|█████████▉| 14.0G/14.0G [01:35<00:00, 157MB/s] \nDownloading: 100%|██████████| 8.86k/8.86k [00:00<00:00, 11.4MB/s]\nDownloading: 100%|██████████| 10.3k/10.3k [00:00<00:00, 14.2MB/s]\nDownloading: 100%|██████████| 548/548 [00:00<00:00, 2.40MB/s]\nDownloading: 100%|██████████| 9.41k/9.41k [00:00<00:00, 13.7MB/s]\nDownloading: 100%|██████████| 1.91M/1.91M [00:00<00:00, 6.00MB/s]\nDownloading: 100%|██████████| 795/795 [00:00<00:00, 2.92MB/s]\n2024-05-08 22:56:08,917 - modelscope - INFO - initialize model from /root/.cache/modelscope/hub/baichuan-inc/Baichuan2-7B-Chat\n2024-05-08 22:56:10,500 - modelscope - WARNING - ('MODELS', 'text-generation', 'Baichuan2-7B-Chat') not found in ast index file\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n2024-05-08 22:56:45.152394: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-08 22:56:45.153143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-08 22:56:45.318120: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"{'response': '\"温故而知新\"是一句中国古代的成语，出自《论语·为政》。这句话的意思是：通过回顾过去的事物，可以了解到新的知识和道理。这个成语强调了学习和记忆的重要性，以及通过不断复习和思考来提高自己的知识水平。\\n\\n在现代教育中，这句话仍然具有很大的启示意义。学习是一个持续的过程，我们需要不断地回顾和巩固过去的知识，以便更好地理解和掌握新的知识。同时，通过温故，我们还可以发现过去知识的不足和遗漏，从而激发我们的求知欲和创新精神。\\n\\n总之，\"温故而知新\"是一种有效的学习方法和策略，可以帮助我们在不断变化的世界中保持知识和技能的更新和提升。', 'history': [{'role': 'user', 'content': '讲解一下“温故而知新”'}, {'role': 'assistant', 'content': '\"温故而知新\"是一句中国古代的成语，出自《论语·为政》。这句话的意思是：通过回顾过去的事物，可以了解到新的知识和道理。这个成语强调了学习和记忆的重要性，以及通过不断复习和思考来提高自己的知识水平。\\n\\n在现代教育中，这句话仍然具有很大的启示意义。学习是一个持续的过程，我们需要不断地回顾和巩固过去的知识，以便更好地理解和掌握新的知识。同时，通过温故，我们还可以发现过去知识的不足和遗漏，从而激发我们的求知欲和创新精神。\\n\\n总之，\"温故而知新\"是一种有效的学习方法和策略，可以帮助我们在不断变化的世界中保持知识和技能的更新和提升。'}]}\n","output_type":"stream"}]},{"cell_type":"code","source":"content = '''Using the contexts below, answer the query.\n\ncontexts:\nhave taken both these aspects into account. We\nhave expanded the vocabulary size from 64,000\nin Baichuan 1 to 125,696, aiming to strike a\nbalance between computational efficiency and\nmodel performance.\nTokenizer V ocab Size Compression Rate ↓\nLLaMA 2 32,000 1.037\nBloom 250,680 0.501\nimprove after training on more than 2.6 trillion\ntokens. By sharing these intermediary results,\nwe hope to provide the community with greater\ninsight into the training dynamics of Baichuan 2.\nUnderstanding these dynamics is key to unraveling\nthe inner working mechanism of large language\nBaichuan 2: Open Large-scale Language Models\nAiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan\nDian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai\nGuosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji\n\nquery: How large is the baichuan2 vocabulary size?\n'''","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:57:06.232177Z","iopub.execute_input":"2024-05-08T22:57:06.232873Z","iopub.status.idle":"2024-05-08T22:57:06.240982Z","shell.execute_reply.started":"2024-05-08T22:57:06.232841Z","shell.execute_reply":"2024-05-08T22:57:06.239842Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"messages = []\nmessages.append({\"role\": \"user\", \"content\": content})\nresponse = model(messages)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:57:06.242464Z","iopub.execute_input":"2024-05-08T22:57:06.243218Z","iopub.status.idle":"2024-05-08T22:57:08.086496Z","shell.execute_reply.started":"2024-05-08T22:57:06.243184Z","shell.execute_reply":"2024-05-08T22:57:08.085468Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"{'response': 'The vocabulary size for Baichuan 2 is 125,696.', 'history': [{'role': 'user', 'content': 'Using the contexts below, answer the query.\\n\\ncontexts:\\nhave taken both these aspects into account. We\\nhave expanded the vocabulary size from 64,000\\nin Baichuan 1 to 125,696, aiming to strike a\\nbalance between computational efficiency and\\nmodel performance.\\nTokenizer V ocab Size Compression Rate ↓\\nLLaMA 2 32,000 1.037\\nBloom 250,680 0.501\\nimprove after training on more than 2.6 trillion\\ntokens. By sharing these intermediary results,\\nwe hope to provide the community with greater\\ninsight into the training dynamics of Baichuan 2.\\nUnderstanding these dynamics is key to unraveling\\nthe inner working mechanism of large language\\nBaichuan 2: Open Large-scale Language Models\\nAiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan\\nDian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai\\nGuosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji\\n\\nquery: How large is the baichuan2 vocabulary size?\\n'}, {'role': 'assistant', 'content': 'The vocabulary size for Baichuan 2 is 125,696.'}]}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}